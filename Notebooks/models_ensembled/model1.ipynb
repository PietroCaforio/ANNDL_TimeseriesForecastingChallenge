{
  "metadata": {
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [
        {
          "sourceId": 7176744,
          "sourceType": "datasetVersion",
          "datasetId": 4147411
        }
      ],
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "papermill": {
      "default_parameters": {},
      "duration": 7055.08191,
      "end_time": "2023-12-18T10:28:07.950210",
      "environment_variables": {},
      "exception": null,
      "input_path": "__notebook__.ipynb",
      "output_path": "__notebook__.ipynb",
      "parameters": {},
      "start_time": "2023-12-18T08:30:32.868300",
      "version": "2.4.0"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Fix randomness and hide warnings\n",
        "seed = 42\n",
        "\n",
        "import os\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
        "os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "os.environ['MPLCONFIGDIR'] = os.getcwd()+'/configs/'\n",
        "\n",
        "import warnings\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
        "warnings.simplefilter(action='ignore', category=Warning)\n",
        "\n",
        "import numpy as np\n",
        "np.random.seed(seed)\n",
        "\n",
        "import logging\n",
        "\n",
        "import random\n",
        "random.seed(seed)"
      ],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-12-18T08:30:36.098600Z",
          "iopub.status.busy": "2023-12-18T08:30:36.097843Z",
          "iopub.status.idle": "2023-12-18T08:30:36.109513Z",
          "shell.execute_reply": "2023-12-18T08:30:36.108847Z"
        },
        "papermill": {
          "duration": 0.023965,
          "end_time": "2023-12-18T08:30:36.111447",
          "exception": false,
          "start_time": "2023-12-18T08:30:36.087482",
          "status": "completed"
        },
        "tags": [],
        "id": "m9wZfwVzZHSU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import tensorflow\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras as tfk\n",
        "from tensorflow.keras import layers as tfkl\n",
        "tf.autograph.set_verbosity(0)\n",
        "tf.get_logger().setLevel(logging.ERROR)\n",
        "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n",
        "tf.random.set_seed(seed)\n",
        "tf.compat.v1.set_random_seed(seed)\n",
        "print(tf.__version__)"
      ],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-12-18T08:30:36.129522Z",
          "iopub.status.busy": "2023-12-18T08:30:36.128983Z",
          "iopub.status.idle": "2023-12-18T08:30:47.393919Z",
          "shell.execute_reply": "2023-12-18T08:30:47.392737Z"
        },
        "papermill": {
          "duration": 11.276103,
          "end_time": "2023-12-18T08:30:47.396024",
          "exception": false,
          "start_time": "2023-12-18T08:30:36.119921",
          "status": "completed"
        },
        "tags": [],
        "id": "Kmox2a3sZHSY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "plt.rc('font', size=16)\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.preprocessing import RobustScaler"
      ],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-12-18T08:30:47.414769Z",
          "iopub.status.busy": "2023-12-18T08:30:47.414188Z",
          "iopub.status.idle": "2023-12-18T08:30:48.455021Z",
          "shell.execute_reply": "2023-12-18T08:30:48.454195Z"
        },
        "papermill": {
          "duration": 1.052622,
          "end_time": "2023-12-18T08:30:48.457248",
          "exception": false,
          "start_time": "2023-12-18T08:30:47.404626",
          "status": "completed"
        },
        "tags": [],
        "id": "7QT21RWgZHSY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Load data"
      ],
      "metadata": {
        "id": "xo3tdY6PZK08"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = np.load('/kaggle/input/datasetchallengeann2/training_dataset/training_data.npy')\n",
        "data.shape"
      ],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-12-18T08:30:48.475368Z",
          "iopub.status.busy": "2023-12-18T08:30:48.475087Z",
          "iopub.status.idle": "2023-12-18T08:30:59.652563Z",
          "shell.execute_reply": "2023-12-18T08:30:59.651631Z"
        },
        "papermill": {
          "duration": 11.188912,
          "end_time": "2023-12-18T08:30:59.654788",
          "exception": false,
          "start_time": "2023-12-18T08:30:48.465876",
          "status": "completed"
        },
        "tags": [],
        "id": "4y-RB_AxZHSZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "categories = np.load('/kaggle/input/datasetchallengeann2/training_dataset/categories.npy')\n",
        "valid_indices = np.load('/kaggle/input/datasetchallengeann2/training_dataset/valid_periods.npy')\n",
        "print(categories.shape)\n",
        "print(valid_indices.shape)"
      ],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-12-18T08:30:59.673610Z",
          "iopub.status.busy": "2023-12-18T08:30:59.672986Z",
          "iopub.status.idle": "2023-12-18T08:30:59.689153Z",
          "shell.execute_reply": "2023-12-18T08:30:59.688124Z"
        },
        "papermill": {
          "duration": 0.027533,
          "end_time": "2023-12-18T08:30:59.691080",
          "exception": false,
          "start_time": "2023-12-18T08:30:59.663547",
          "status": "completed"
        },
        "tags": [],
        "id": "ljVjI1neZHSd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Plot data"
      ],
      "metadata": {
        "id": "ElD62O8PZY2G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_random_timeseries(data, labels, types=('A', 'B', 'C', 'D', 'E')):\n",
        "    \"\"\"\n",
        "    Plot one random time series for each type specified in 'types'.\n",
        "\n",
        "    Parameters:\n",
        "    - data: numpy array of shape (num_time_series, time_series_length)\n",
        "    - labels: numpy array of shape (num_time_series,) representing the type for each time series\n",
        "    - types: tuple specifying the types to plot (default is ('A', 'B', 'C', 'D', 'E'))\n",
        "    \"\"\"\n",
        "    # Create a figure with subplots for each type\n",
        "    fig, axs = plt.subplots(len(types), 1, figsize=(10, 2 * len(types)), sharex=True, sharey=True)\n",
        "\n",
        "    # Loop through each type and plot a random time series of that type\n",
        "    for i, t in enumerate(types):\n",
        "        # Get indices of time series with the specified type\n",
        "        type_indices = np.where(labels == t)[0]\n",
        "\n",
        "        # Select a random index for the given type\n",
        "        random_index = np.random.choice(type_indices)\n",
        "\n",
        "        # Extract the time series data\n",
        "        time_series = data[random_index, valid_indices[random_index, 0]:]\n",
        "\n",
        "        # Plot the time series\n",
        "        axs[i].plot(time_series)\n",
        "        axs[i].set_title(f'Type {t}')\n",
        "\n",
        "    # Adjust layout and show the plot\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "plot_random_timeseries(data, categories)"
      ],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-12-18T08:30:59.804179Z",
          "iopub.status.busy": "2023-12-18T08:30:59.803939Z",
          "iopub.status.idle": "2023-12-18T08:31:00.991798Z",
          "shell.execute_reply": "2023-12-18T08:31:00.990886Z"
        },
        "papermill": {
          "duration": 1.199414,
          "end_time": "2023-12-18T08:31:00.994105",
          "exception": false,
          "start_time": "2023-12-18T08:30:59.794691",
          "status": "completed"
        },
        "tags": [],
        "id": "aDM2XiJgZHSz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Randomly select 10 time series indices\n",
        "random_indices = np.random.choice(data.shape[0], 10, replace=False)\n",
        "\n",
        "# Plot each selected time series in a separate subplot\n",
        "num_plots = len(random_indices)\n",
        "fig, axs = plt.subplots(num_plots, 1, figsize=(10, 2 * num_plots))\n",
        "\n",
        "for i, index in enumerate(random_indices):\n",
        "    axs[i].plot(data[index, valid_indices[index, 0]:])\n",
        "    axs[i].set_title(f'Time Series {index}')\n",
        "    axs[i].set_xlabel('Time')\n",
        "    axs[i].set_ylabel('Value')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-12-18T08:31:01.015935Z",
          "iopub.status.busy": "2023-12-18T08:31:01.015656Z",
          "iopub.status.idle": "2023-12-18T08:31:02.812503Z",
          "shell.execute_reply": "2023-12-18T08:31:02.811596Z"
        },
        "papermill": {
          "duration": 1.812629,
          "end_time": "2023-12-18T08:31:02.816894",
          "exception": false,
          "start_time": "2023-12-18T08:31:01.004265",
          "status": "completed"
        },
        "tags": [],
        "id": "TYkqTc5wZHSz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Build sequences"
      ],
      "metadata": {
        "id": "fgOVpt8zZdtA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_sequences(df, window=100, stride=20, telescope=100):\n",
        "    global count_inspect\n",
        "    # Sanity check to avoid runtime errors\n",
        "    assert window % stride == 0\n",
        "    dataset = []\n",
        "    labels = []\n",
        "    df = np.expand_dims(df, axis = -1)\n",
        "    temp_df = np.copy(df)\n",
        "    padding_check = len(df)%(window+telescope) #compute a boolean that says if the padding needs to be done\n",
        "\n",
        "    if(padding_check != 0):\n",
        "        # Compute padding length\n",
        "        padding_len = window+telescope - len(df)%(window+telescope) # compute padding length\n",
        "        padding = np.array([]) #padding starts empty\n",
        "        padding = np.expand_dims(padding, axis=-1)\n",
        "        if(padding_len//len(temp_df)>0): #If the whole timeseries can be copied entirely an integer number of times (at least 1)...\n",
        "            for i in range(0,padding_len//len(temp_df)):\n",
        "                noise = np.random.normal(0,1, (len(temp_df),1)) #generate some random noise\n",
        "                sum_ = np.sum([temp_df,noise], axis = 0) #copy the whole timeseries and add the noise to it\n",
        "                padding = np.concatenate((sum_,padding)) #concatenate the new padding piece with the padding up to now\n",
        "\n",
        "        if(padding_len % len(temp_df) !=0): #if still there is some gap to fill, but the timeseries doesn't fit entirely\n",
        "            noise = np.random.normal(0,1, (padding_len % len(temp_df),1)) #generate some random noise\n",
        "            last_copy = temp_df[-(padding_len % len(temp_df)):] #copy a piece of the timeseries large enough to fill the gap\n",
        "            last_pad = np.sum([last_copy, noise], axis = 0) #add the noise\n",
        "            padding = np.concatenate((last_pad,padding)) #concatenate the new padding piece with the padding up to now\n",
        "        if(np.max(padding)-np.min(padding) != 0):  #check to avoid division by zero\n",
        "            padding = (padding - np.min(padding))/np.ptp(padding) #normalize the padding\n",
        "\n",
        "        temp_df = np.concatenate((padding,df)) #concatenate the padding to the timeseries\n",
        "        assert len(temp_df) % (window+telescope) == 0 #verify we have correctly padded\n",
        "\n",
        "    for idx in np.arange(0,len(temp_df)-window-telescope +1 ,stride):\n",
        "        dataset.append(temp_df[idx:idx+window]) #take the first piece of length <window> as data\n",
        "        labels.append(temp_df[idx+window:idx+window+telescope]) #take the following piece as telescope\n",
        "\n",
        "    dataset = np.array(dataset)\n",
        "    labels = np.array(labels)\n",
        "    return dataset, labels #return data"
      ],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-12-18T08:31:02.844514Z",
          "iopub.status.busy": "2023-12-18T08:31:02.844215Z",
          "iopub.status.idle": "2023-12-18T08:31:02.856444Z",
          "shell.execute_reply": "2023-12-18T08:31:02.855630Z"
        },
        "papermill": {
          "duration": 0.02833,
          "end_time": "2023-12-18T08:31:02.858310",
          "exception": false,
          "start_time": "2023-12-18T08:31:02.829980",
          "status": "completed"
        },
        "tags": [],
        "id": "6IoFWj6ZZHSz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Split train and test"
      ],
      "metadata": {
        "id": "U6J6Yhp-aFKY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train_raw, X_validation_raw, valid_indices_train, valid_indices_validation = train_test_split(data, valid_indices, test_size = 0.2)\n",
        "print(X_train_raw.shape, X_validation_raw.shape)"
      ],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-12-18T08:31:15.395346Z",
          "iopub.status.busy": "2023-12-18T08:31:15.394529Z",
          "iopub.status.idle": "2023-12-18T08:31:15.721480Z",
          "shell.execute_reply": "2023-12-18T08:31:15.720308Z"
        },
        "papermill": {
          "duration": 0.343334,
          "end_time": "2023-12-18T08:31:15.723529",
          "exception": false,
          "start_time": "2023-12-18T08:31:15.380195",
          "status": "completed"
        },
        "tags": [],
        "id": "T3UbXPo1ZHS0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Find window"
      ],
      "metadata": {
        "id": "UiUTXkLpaP7j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def find_window(time_series,threshold):#Here we compute the autocorrelation function in order to find the right window setting a threshold\n",
        "    autocorr = np.correlate(time_series,time_series, mode = 'full')\n",
        "    autocorr /= autocorr[int(len(autocorr)/2)]\n",
        "    autocorr = autocorr[int(len(autocorr)/2):]\n",
        "    window = np.argmax(autocorr <= threshold)\n",
        "    return window"
      ],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-12-18T08:30:59.709323Z",
          "iopub.status.busy": "2023-12-18T08:30:59.709060Z",
          "iopub.status.idle": "2023-12-18T08:30:59.714187Z",
          "shell.execute_reply": "2023-12-18T08:30:59.713360Z"
        },
        "papermill": {
          "duration": 0.016459,
          "end_time": "2023-12-18T08:30:59.716133",
          "exception": false,
          "start_time": "2023-12-18T08:30:59.699674",
          "status": "completed"
        },
        "tags": [],
        "id": "FWUvI09OZHSe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "windows = []\n",
        "for time_series in X_train_raw:\n",
        "    windows.append(find_window(time_series,threshold=0.1))\n",
        "\n",
        "print(\"Mean window\",np.mean(np.array(windows))) #The autocorrelations will be different, in order to find an unique window we averaged them"
      ],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-12-18T08:31:15.912912Z",
          "iopub.status.busy": "2023-12-18T08:31:15.912138Z",
          "iopub.status.idle": "2023-12-18T08:31:51.468788Z",
          "shell.execute_reply": "2023-12-18T08:31:51.467823Z"
        },
        "papermill": {
          "duration": 35.586506,
          "end_time": "2023-12-18T08:31:51.483737",
          "exception": false,
          "start_time": "2023-12-18T08:31:15.897231",
          "status": "completed"
        },
        "tags": [],
        "id": "H_NO94IIZHS0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mean_window = 150#Hard coded due to practical purposes"
      ],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-12-18T08:30:59.781128Z",
          "iopub.status.busy": "2023-12-18T08:30:59.780886Z",
          "iopub.status.idle": "2023-12-18T08:30:59.784305Z",
          "shell.execute_reply": "2023-12-18T08:30:59.783504Z"
        },
        "papermill": {
          "duration": 0.014967,
          "end_time": "2023-12-18T08:30:59.786203",
          "exception": false,
          "start_time": "2023-12-18T08:30:59.771236",
          "status": "completed"
        },
        "tags": [],
        "id": "u517nrRfZHSy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Define autoregressive telescope and build sequences"
      ],
      "metadata": {
        "id": "CyZuVTItaSWQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "autoregressive_telescope=6"
      ],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-12-18T08:31:15.874607Z",
          "iopub.status.busy": "2023-12-18T08:31:15.873900Z",
          "iopub.status.idle": "2023-12-18T08:31:15.879541Z",
          "shell.execute_reply": "2023-12-18T08:31:15.878135Z"
        },
        "papermill": {
          "duration": 0.031042,
          "end_time": "2023-12-18T08:31:15.882299",
          "exception": false,
          "start_time": "2023-12-18T08:31:15.851257",
          "status": "completed"
        },
        "tags": [],
        "id": "_M01U85vZHS0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = []\n",
        "y_train = []\n",
        "for i, time_series in enumerate(X_train_raw):#We repeat the function build_sequences for each time series in the entire training set\n",
        "    dataset_tmp, labels_tmp = build_sequences(time_series[valid_indices_train[i, 0]:], window = mean_window, stride = 3, telescope = autoregressive_telescope)\n",
        "    X_train.extend(dataset_tmp)\n",
        "    y_train.extend(labels_tmp)\n",
        "X_train = np.array(X_train)\n",
        "y_train = np.array(y_train)"
      ],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-12-18T08:31:51.511344Z",
          "iopub.status.busy": "2023-12-18T08:31:51.511056Z",
          "iopub.status.idle": "2023-12-18T08:32:05.308049Z",
          "shell.execute_reply": "2023-12-18T08:32:05.307158Z"
        },
        "papermill": {
          "duration": 13.81333,
          "end_time": "2023-12-18T08:32:05.310428",
          "exception": false,
          "start_time": "2023-12-18T08:31:51.497098",
          "status": "completed"
        },
        "tags": [],
        "id": "G0B4b_-WZHS0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_val = []\n",
        "y_val = []\n",
        "for i, time_series in enumerate(X_validation_raw):#We repeat the function build_sequences for each time series in the entire validation set\n",
        "    dataset_tmp, labels_tmp = build_sequences(time_series[valid_indices_validation[i, 0]:], window = mean_window, stride = 3, telescope = autoregressive_telescope)\n",
        "    X_val.extend(dataset_tmp)\n",
        "    y_val.extend(labels_tmp)\n",
        "X_val = np.array(X_val)\n",
        "y_val = np.array(y_val)"
      ],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-12-18T08:32:05.339150Z",
          "iopub.status.busy": "2023-12-18T08:32:05.338263Z",
          "iopub.status.idle": "2023-12-18T08:32:08.413401Z",
          "shell.execute_reply": "2023-12-18T08:32:08.412496Z"
        },
        "papermill": {
          "duration": 3.091381,
          "end_time": "2023-12-18T08:32:08.415574",
          "exception": false,
          "start_time": "2023-12-18T08:32:05.324193",
          "status": "completed"
        },
        "tags": [],
        "id": "kuLtl8BqZHS1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_shape = X_train.shape[1:]\n",
        "output_shape = y_train.shape[1:]\n",
        "batch_size = 1024\n",
        "epochs = 300"
      ],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-12-18T08:32:08.477187Z",
          "iopub.status.busy": "2023-12-18T08:32:08.476931Z",
          "iopub.status.idle": "2023-12-18T08:32:08.481222Z",
          "shell.execute_reply": "2023-12-18T08:32:08.480388Z"
        },
        "papermill": {
          "duration": 0.020191,
          "end_time": "2023-12-18T08:32:08.483166",
          "exception": false,
          "start_time": "2023-12-18T08:32:08.462975",
          "status": "completed"
        },
        "tags": [],
        "id": "Rfw8sukuZHS1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Inspect sequences"
      ],
      "metadata": {
        "id": "OhGfMSeZagFa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def inspect_multivariate(X, y, telescope, idx=None):\n",
        "    random_indices = np.random.choice(X.shape[0], 10, replace=False)\n",
        "\n",
        "    # Plot each selected time series in a separate subplot\n",
        "    num_plots = len(random_indices)\n",
        "    fig, axs = plt.subplots(num_plots, 1, figsize=(10, 2 * num_plots))\n",
        "\n",
        "    for i, index in enumerate(random_indices):\n",
        "        axs[i].plot(np.arange(len(X[0,:])), X[index,:])\n",
        "        axs[i].scatter(np.arange(len(X[0,:]), len(X[0,:])+telescope), y[index,:], color='orange')\n",
        "        axs[i].set_title(f'Time Series {index}')\n",
        "        axs[i].set_xlabel('Time')\n",
        "        axs[i].set_ylabel('Value')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-12-18T08:32:08.543389Z",
          "iopub.status.busy": "2023-12-18T08:32:08.543104Z",
          "iopub.status.idle": "2023-12-18T08:32:08.550438Z",
          "shell.execute_reply": "2023-12-18T08:32:08.549610Z"
        },
        "papermill": {
          "duration": 0.023204,
          "end_time": "2023-12-18T08:32:08.552383",
          "exception": false,
          "start_time": "2023-12-18T08:32:08.529179",
          "status": "completed"
        },
        "tags": [],
        "id": "EcZbhCH_ZHS1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inspect_multivariate(X_train, y_train, autoregressive_telescope)"
      ],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-12-18T08:32:08.579425Z",
          "iopub.status.busy": "2023-12-18T08:32:08.579177Z",
          "iopub.status.idle": "2023-12-18T08:32:10.571841Z",
          "shell.execute_reply": "2023-12-18T08:32:10.571034Z"
        },
        "papermill": {
          "duration": 2.011585,
          "end_time": "2023-12-18T08:32:10.576983",
          "exception": false,
          "start_time": "2023-12-18T08:32:08.565398",
          "status": "completed"
        },
        "tags": [],
        "id": "4z4AJT_eZHS1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Build and train model"
      ],
      "metadata": {
        "id": "Dp1dJ-2_aleA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_resnet(input_shape, n_feature_maps = 64):\n",
        "\n",
        "    input_layer = tfkl.Input(input_shape)\n",
        "\n",
        "    # BLOCK 1\n",
        "\n",
        "    conv_x = tfkl.Conv1D(filters=n_feature_maps, kernel_size=8, padding='same')(input_layer)\n",
        "    conv_x = tfkl.BatchNormalization()(conv_x)\n",
        "    conv_x = tfkl.Activation('relu')(conv_x)\n",
        "\n",
        "    conv_y = tfkl.Conv1D(filters=n_feature_maps, kernel_size=5, padding='same')(conv_x)\n",
        "    conv_y = tfkl.BatchNormalization()(conv_y)\n",
        "    conv_y = tfkl.Activation('relu')(conv_y)\n",
        "\n",
        "    conv_z = tfkl.Conv1D(filters=n_feature_maps, kernel_size=3, padding='same')(conv_y)\n",
        "    conv_z = tfkl.BatchNormalization()(conv_z)\n",
        "\n",
        "    # expand channels for the sum\n",
        "    shortcut_y = tfkl.Conv1D(filters=n_feature_maps, kernel_size=1, padding='same')(input_layer)\n",
        "    shortcut_y = tfkl.BatchNormalization()(shortcut_y)\n",
        "\n",
        "    output_block_1 = tfkl.add([shortcut_y, conv_z])\n",
        "    output_block_1 = tfkl.Activation('relu')(output_block_1)\n",
        "\n",
        "    # BLOCK 2\n",
        "\n",
        "    conv_x = tfkl.Conv1D(filters=n_feature_maps * 2, kernel_size=8, padding='same')(output_block_1)\n",
        "    conv_x = tfkl.BatchNormalization()(conv_x)\n",
        "    conv_x = tfkl.Activation('relu')(conv_x)\n",
        "\n",
        "    conv_y = tfkl.Conv1D(filters=n_feature_maps * 2, kernel_size=5, padding='same')(conv_x)\n",
        "    conv_y = tfkl.BatchNormalization()(conv_y)\n",
        "    conv_y = tfkl.Activation('relu')(conv_y)\n",
        "\n",
        "    conv_z = tfkl.Conv1D(filters=n_feature_maps * 2, kernel_size=3, padding='same')(conv_y)\n",
        "    conv_z = tfkl.BatchNormalization()(conv_z)\n",
        "\n",
        "    # expand channels for the sum\n",
        "    shortcut_y = tfkl.Conv1D(filters=n_feature_maps * 2, kernel_size=1, padding='same')(output_block_1)\n",
        "    shortcut_y = tfkl.BatchNormalization()(shortcut_y)\n",
        "\n",
        "    output_block_2 = tfkl.add([shortcut_y, conv_z])\n",
        "    output_block_2 = tfkl.Activation('relu')(output_block_2)\n",
        "\n",
        "    # BLOCK 3\n",
        "\n",
        "    conv_x = tfkl.Conv1D(filters=n_feature_maps * 2, kernel_size=8, padding='same')(output_block_2)\n",
        "    conv_x = tfkl.BatchNormalization()(conv_x)\n",
        "    conv_x = tfkl.Activation('relu')(conv_x)\n",
        "\n",
        "    conv_y = tfkl.Conv1D(filters=n_feature_maps * 2, kernel_size=5, padding='same')(conv_x)\n",
        "    conv_y = tfkl.BatchNormalization()(conv_y)\n",
        "    conv_y = tfkl.Activation('relu')(conv_y)\n",
        "\n",
        "    conv_z = tfkl.Conv1D(filters=n_feature_maps * 2, kernel_size=3, padding='same')(conv_y)\n",
        "    conv_z = tfkl.BatchNormalization()(conv_z)\n",
        "\n",
        "    # no need to expand channels because they are equal\n",
        "    shortcut_y = tfkl.BatchNormalization()(output_block_2)\n",
        "\n",
        "    output_block_3 = tfkl.add([shortcut_y, conv_z])\n",
        "    output_block_3 = tfkl.Activation('relu')(output_block_3)\n",
        "\n",
        "    # FINAL\n",
        "\n",
        "    out = tfkl.GlobalAveragePooling1D()(output_block_3)\n",
        "\n",
        "    print ('        -- model was built.')\n",
        "    return input_layer, out"
      ],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-12-18T08:32:10.614386Z",
          "iopub.status.busy": "2023-12-18T08:32:10.614068Z",
          "iopub.status.idle": "2023-12-18T08:32:10.628537Z",
          "shell.execute_reply": "2023-12-18T08:32:10.627769Z"
        },
        "papermill": {
          "duration": 0.035332,
          "end_time": "2023-12-18T08:32:10.630383",
          "exception": false,
          "start_time": "2023-12-18T08:32:10.595051",
          "status": "completed"
        },
        "tags": [],
        "id": "v895Gh_vZHS2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class reduce_sum(tfkl.Layer):\n",
        "    def call(self,x):\n",
        "        return tf.reduce_sum(x,axis=1)"
      ],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-12-18T08:32:10.665878Z",
          "iopub.status.busy": "2023-12-18T08:32:10.665571Z",
          "iopub.status.idle": "2023-12-18T08:32:10.670084Z",
          "shell.execute_reply": "2023-12-18T08:32:10.669350Z"
        },
        "papermill": {
          "duration": 0.024441,
          "end_time": "2023-12-18T08:32:10.671879",
          "exception": false,
          "start_time": "2023-12-18T08:32:10.647438",
          "status": "completed"
        },
        "tags": [],
        "id": "eNL4EH2sZHS2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_CONV_LSTM_model(input_shape, output_shape, n_resnet_features = 32,n_features = 64):\n",
        "    #merge convolution and lstm, to extract features and correlate in the time domain\n",
        "    # Ensure the input time steps are at least as many as the output time steps\n",
        "    assert input_shape[0] >= output_shape[0]\n",
        "\n",
        "    input_layer, embedding = build_resnet(input_shape,n_resnet_features)\n",
        "\n",
        "    embedding = tf.expand_dims(embedding,-1)\n",
        "    # Add a Bidirectional LSTM layer with 64 units\n",
        "    x = tfkl.Bidirectional(tfkl.LSTM(n_features, return_sequences=True, name='lstm'), name='bidirectional_lstm')(embedding)\n",
        "\n",
        "    #Attention mechanism\n",
        "    attention = tfkl.Dense(1, activation='tanh')(x)\n",
        "    attention = tfkl.Flatten()(attention)\n",
        "    attention = tfkl.Activation('softmax')(attention)\n",
        "    attention = tfkl.RepeatVector(n_features*2)(attention)\n",
        "    attention = tfkl.Permute([2, 1])(attention)\n",
        "    attention = tfkl.Multiply()([x, attention])\n",
        "    attention = reduce_sum()(attention)\n",
        "    output_layer = tfkl.Dense(output_shape[0])(attention)\n",
        "\n",
        "    # Construct the model by connecting input and output layers\n",
        "    model = tf.keras.Model(inputs=input_layer, outputs=output_layer, name='CONV_LSTM_model')\n",
        "\n",
        "    # Compile the model with Mean Squared Error loss and Adam optimizer\n",
        "    model.compile(loss=tf.keras.losses.MeanSquaredError(), optimizer=tf.keras.optimizers.Adam())\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-12-18T08:32:10.706932Z",
          "iopub.status.busy": "2023-12-18T08:32:10.706660Z",
          "iopub.status.idle": "2023-12-18T08:32:10.716595Z",
          "shell.execute_reply": "2023-12-18T08:32:10.715864Z"
        },
        "papermill": {
          "duration": 0.02959,
          "end_time": "2023-12-18T08:32:10.718460",
          "exception": false,
          "start_time": "2023-12-18T08:32:10.688870",
          "status": "completed"
        },
        "tags": [],
        "id": "UaYs1EphZHS2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = build_CONV_LSTM_model(input_shape, output_shape, n_features = 128)\n",
        "model.summary()\n",
        "tfk.utils.plot_model(model, expand_nested=True, show_shapes=True)"
      ],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-12-18T08:32:10.796048Z",
          "iopub.status.busy": "2023-12-18T08:32:10.795719Z",
          "iopub.status.idle": "2023-12-18T08:32:14.935882Z",
          "shell.execute_reply": "2023-12-18T08:32:14.934974Z"
        },
        "papermill": {
          "duration": 4.167082,
          "end_time": "2023-12-18T08:32:14.944579",
          "exception": false,
          "start_time": "2023-12-18T08:32:10.777497",
          "status": "completed"
        },
        "tags": [],
        "id": "6CAnqveqZHS2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "history = model.fit(\n",
        "    x = X_train,\n",
        "    y = y_train,\n",
        "    batch_size = batch_size,\n",
        "    epochs = epochs,\n",
        "    validation_data=(X_val, y_val),\n",
        "    callbacks = [\n",
        "        tfk.callbacks.EarlyStopping(monitor='val_loss', mode='min', patience=12, restore_best_weights=True),\n",
        "        tfk.callbacks.ReduceLROnPlateau(monitor='val_loss', mode='min', patience=10, factor=0.1, min_lr=1e-5)\n",
        "    ]\n",
        ").history"
      ],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-12-18T08:32:15.016141Z",
          "iopub.status.busy": "2023-12-18T08:32:15.015829Z",
          "iopub.status.idle": "2023-12-18T10:27:48.454922Z",
          "shell.execute_reply": "2023-12-18T10:27:48.453743Z"
        },
        "papermill": {
          "duration": 6933.476954,
          "end_time": "2023-12-18T10:27:48.457039",
          "exception": false,
          "start_time": "2023-12-18T08:32:14.980085",
          "status": "completed"
        },
        "tags": [],
        "id": "Jm1j8yBVZHS2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('forecasting_all_resnet_aug.h5')"
      ],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-12-18T10:27:58.919996Z",
          "iopub.status.busy": "2023-12-18T10:27:58.919093Z",
          "iopub.status.idle": "2023-12-18T10:27:59.077293Z",
          "shell.execute_reply": "2023-12-18T10:27:59.076489Z"
        },
        "papermill": {
          "duration": 5.439247,
          "end_time": "2023-12-18T10:27:59.079624",
          "exception": false,
          "start_time": "2023-12-18T10:27:53.640377",
          "status": "completed"
        },
        "tags": [],
        "id": "7y7m57xVZHS2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}