{"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":7176744,"sourceType":"datasetVersion","datasetId":4147411}],"dockerImageVersionId":30616,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"},"papermill":{"default_parameters":{},"duration":1534.946445,"end_time":"2023-12-11T19:32:29.813273","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2023-12-11T19:06:54.866828","version":"2.4.0"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Fix randomness and hide warnings\nseed = 42\n\nimport os\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\nos.environ['PYTHONHASHSEED'] = str(seed)\nos.environ['MPLCONFIGDIR'] = os.getcwd()+'/configs/'\n\nimport warnings\nwarnings.simplefilter(action='ignore', category=FutureWarning)\nwarnings.simplefilter(action='ignore', category=Warning)\n\nimport numpy as np\nnp.random.seed(seed)\n\nimport logging\n\nimport random\nrandom.seed(seed)","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","papermill":{"duration":0.024366,"end_time":"2023-12-11T19:06:58.324076","exception":false,"start_time":"2023-12-11T19:06:58.299710","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-12-12T19:14:10.862193Z","iopub.execute_input":"2023-12-12T19:14:10.862591Z","iopub.status.idle":"2023-12-12T19:14:10.875221Z","shell.execute_reply.started":"2023-12-12T19:14:10.862558Z","shell.execute_reply":"2023-12-12T19:14:10.874303Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Import tensorflow\nimport tensorflow as tf\nfrom tensorflow import keras as tfk\nfrom tensorflow.keras import layers as tfkl\ntf.autograph.set_verbosity(0)\ntf.get_logger().setLevel(logging.ERROR)\ntf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\ntf.random.set_seed(seed)\ntf.compat.v1.set_random_seed(seed)\nprint(tf.__version__)","metadata":{"papermill":{"duration":12.573897,"end_time":"2023-12-11T19:07:10.906016","exception":false,"start_time":"2023-12-11T19:06:58.332119","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-12-12T19:14:12.857508Z","iopub.execute_input":"2023-12-12T19:14:12.857880Z","iopub.status.idle":"2023-12-12T19:14:24.291079Z","shell.execute_reply.started":"2023-12-12T19:14:12.857826Z","shell.execute_reply":"2023-12-12T19:14:24.290181Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nplt.rc('font', size=16)\nfrom sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.preprocessing import MinMaxScaler","metadata":{"papermill":{"duration":1.086017,"end_time":"2023-12-11T19:07:11.999694","exception":false,"start_time":"2023-12-11T19:07:10.913677","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-12-12T19:14:24.292901Z","iopub.execute_input":"2023-12-12T19:14:24.293411Z","iopub.status.idle":"2023-12-12T19:14:24.784990Z","shell.execute_reply.started":"2023-12-12T19:14:24.293384Z","shell.execute_reply":"2023-12-12T19:14:24.784037Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = np.load('/kaggle/input/datasetchallengeann2/training_dataset/training_data.npy')\ndata.shape","metadata":{"papermill":{"duration":6.644565,"end_time":"2023-12-11T19:07:18.652038","exception":false,"start_time":"2023-12-11T19:07:12.007473","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-12-12T19:14:24.786095Z","iopub.execute_input":"2023-12-12T19:14:24.786375Z","iopub.status.idle":"2023-12-12T19:14:30.830746Z","shell.execute_reply.started":"2023-12-12T19:14:24.786350Z","shell.execute_reply":"2023-12-12T19:14:30.829878Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"categories = np.load('/kaggle/input/datasetchallengeann2/training_dataset/categories.npy')\nvalid_indices = np.load('/kaggle/input/datasetchallengeann2/training_dataset/valid_periods.npy')\nprint(categories.shape)\nprint(valid_indices.shape)","metadata":{"papermill":{"duration":0.028493,"end_time":"2023-12-11T19:07:18.688376","exception":false,"start_time":"2023-12-11T19:07:18.659883","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-12-12T19:14:30.833252Z","iopub.execute_input":"2023-12-12T19:14:30.834064Z","iopub.status.idle":"2023-12-12T19:14:30.860000Z","shell.execute_reply.started":"2023-12-12T19:14:30.834026Z","shell.execute_reply":"2023-12-12T19:14:30.859037Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\n\ndef plot_random_timeseries(data, labels, types=('A', 'B', 'C', 'D', 'E')):\n    \"\"\"\n    Plot one random time series for each type specified in 'types'.\n\n    Parameters:\n    - data: numpy array of shape (num_time_series, time_series_length)\n    - labels: numpy array of shape (num_time_series,) representing the type for each time series\n    - types: tuple specifying the types to plot (default is ('A', 'B', 'C', 'D', 'E'))\n    \"\"\"\n    # Create a figure with subplots for each type\n    fig, axs = plt.subplots(len(types), 1, figsize=(10, 2 * len(types)), sharex=True, sharey=True)\n\n    # Loop through each type and plot a random time series of that type\n    for i, t in enumerate(types):\n        # Get indices of time series with the specified type\n        type_indices = np.where(labels == t)[0]\n        \n        # Select a random index for the given type\n        random_index = np.random.choice(type_indices)\n        \n        # Extract the time series data\n        time_series = data[random_index, valid_indices[random_index, 0]:]\n        \n        # Plot the time series\n        axs[i].plot(time_series)\n        axs[i].set_title(f'Type {t}')\n\n    # Adjust layout and show the plot\n    plt.tight_layout()\n    plt.show()\n\nplot_random_timeseries(data, categories)","metadata":{"papermill":{"duration":1.414725,"end_time":"2023-12-11T19:07:20.111155","exception":false,"start_time":"2023-12-11T19:07:18.696430","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-12-12T19:14:30.861046Z","iopub.execute_input":"2023-12-12T19:14:30.861326Z","iopub.status.idle":"2023-12-12T19:14:32.165500Z","shell.execute_reply.started":"2023-12-12T19:14:30.861302Z","shell.execute_reply":"2023-12-12T19:14:32.164506Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h3>Training on all</h3>","metadata":{"papermill":{"duration":0.008531,"end_time":"2023-12-11T19:07:20.128702","exception":false,"start_time":"2023-12-11T19:07:20.120171","status":"completed"},"tags":[]}},{"cell_type":"code","source":"#Plot some timeseries to see what they look like\n# Randomly select 10 time series indices\nrandom_indices = np.random.choice(data.shape[0], 10, replace=False)\n\n# Plot each selected time series in a separate subplot\nnum_plots = len(random_indices)\nfig, axs = plt.subplots(num_plots, 1, figsize=(10, 2 * num_plots))\n\nfor i, index in enumerate(random_indices):\n    axs[i].plot(data[index, valid_indices[index, 0]:])\n    axs[i].set_title(f'Time Series {index}')\n    axs[i].set_xlabel('Time')\n    axs[i].set_ylabel('Value')\n\nplt.tight_layout()\nplt.show()","metadata":{"papermill":{"duration":1.878232,"end_time":"2023-12-11T19:07:22.107704","exception":false,"start_time":"2023-12-11T19:07:20.229472","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-12-12T15:56:20.477763Z","iopub.execute_input":"2023-12-12T15:56:20.478146Z","iopub.status.idle":"2023-12-12T15:56:22.265550Z","shell.execute_reply.started":"2023-12-12T15:56:20.478117Z","shell.execute_reply":"2023-12-12T15:56:22.264554Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def build_sequences(df, window=100, stride=20, telescope=100):\n    global count_inspect\n    # Sanity check to avoid runtime errors\n    assert window % stride == 0\n    dataset = []\n    labels = []\n    df = np.expand_dims(df, axis = -1)\n    temp_df = np.copy(df)\n    padding_check = len(df)%(window+telescope) #compute a boolean that says if the padding needs to be done\n\n    if(padding_check != 0):\n        # Compute padding length\n        padding_len = window+telescope - len(df)%(window+telescope) # compute padding length\n        padding = np.array([]) #padding starts empty\n        padding = np.expand_dims(padding, axis=-1)\n        if(padding_len//len(temp_df)>0): #If the whole timeseries can be copied entirely an integer number of times (at least 1)...\n            for i in range(0,padding_len//len(temp_df)):\n                noise = np.random.normal(0,1, (len(temp_df),1)) #generate some random noise\n                sum_ = np.sum([temp_df,noise], axis = 0) #copy the whole timeseries and add the noise to it\n                padding = np.concatenate((sum_,padding)) #concatenate the new padding piece with the padding up to now\n\n        if(padding_len % len(temp_df) !=0): #if still there is some gap to fill, but the timeseries doesn't fit entirely\n            noise = np.random.normal(0,1, (padding_len % len(temp_df),1)) #generate some random noise\n            last_copy = temp_df[-(padding_len % len(temp_df)):] #copy a piece of the timeseries large enough to fill the gap\n            last_pad = np.sum([last_copy, noise], axis = 0) #add the noise\n            padding = np.concatenate((last_pad,padding)) #concatenate the new padding piece with the padding up to now\n        if(np.max(padding)-np.min(padding) != 0):  #check to avoid division by zero\n            padding = (padding - np.min(padding))/np.ptp(padding) #normalize the padding\n\n        temp_df = np.concatenate((padding,df)) #concatenate the padding to the timeseries\n        assert len(temp_df) % (window+telescope) == 0 #verify we have correctly padded\n\n    for idx in np.arange(0,len(temp_df)-window-telescope +1 ,stride):\n        dataset.append(temp_df[idx:idx+window]) #take the first piece of length <window> as data\n        labels.append(temp_df[idx+window:idx+window+telescope]) #take the following piece as telescope\n\n    dataset = np.array(dataset)\n    labels = np.array(labels)\n    return dataset, labels #return data","metadata":{"papermill":{"duration":0.024299,"end_time":"2023-12-11T19:07:22.170522","exception":false,"start_time":"2023-12-11T19:07:22.146223","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-12-12T19:14:32.166931Z","iopub.execute_input":"2023-12-12T19:14:32.167360Z","iopub.status.idle":"2023-12-12T19:14:32.176903Z","shell.execute_reply.started":"2023-12-12T19:14:32.167329Z","shell.execute_reply":"2023-12-12T19:14:32.175743Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train_raw, X_validation_raw, valid_indices_train, valid_indices_validation = train_test_split(data, valid_indices, test_size = 0.2)\nprint(X_train_raw.shape, X_validation_raw.shape)","metadata":{"papermill":{"duration":0.073756,"end_time":"2023-12-11T19:07:22.256921","exception":false,"start_time":"2023-12-11T19:07:22.183165","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-12-12T19:14:32.178278Z","iopub.execute_input":"2023-12-12T19:14:32.179088Z","iopub.status.idle":"2023-12-12T19:14:32.514063Z","shell.execute_reply.started":"2023-12-12T19:14:32.179052Z","shell.execute_reply":"2023-12-12T19:14:32.513052Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(valid_indices_train.shape)","metadata":{"papermill":{"duration":0.021293,"end_time":"2023-12-11T19:07:22.291308","exception":false,"start_time":"2023-12-11T19:07:22.270015","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-12-12T19:14:32.972438Z","iopub.execute_input":"2023-12-12T19:14:32.973261Z","iopub.status.idle":"2023-12-12T19:14:32.977788Z","shell.execute_reply.started":"2023-12-12T19:14:32.973229Z","shell.execute_reply":"2023-12-12T19:14:32.976886Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Compute the lengths of the timeseries\nlengths = []\nfor i in range(len(valid_indices)):\n    lengths.append(valid_indices[i, 1]-valid_indices[i, 0])\nlengths = np.array(lengths)","metadata":{"papermill":{"duration":0.026153,"end_time":"2023-12-11T19:07:22.330714","exception":false,"start_time":"2023-12-11T19:07:22.304561","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-12-12T19:14:34.852183Z","iopub.execute_input":"2023-12-12T19:14:34.852542Z","iopub.status.idle":"2023-12-12T19:14:34.902597Z","shell.execute_reply.started":"2023-12-12T19:14:34.852512Z","shell.execute_reply":"2023-12-12T19:14:34.901874Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(min(lengths), max(lengths)) #print min and max length","metadata":{"papermill":{"duration":0.022758,"end_time":"2023-12-11T19:07:22.366267","exception":false,"start_time":"2023-12-11T19:07:22.343509","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-12-12T19:14:35.062024Z","iopub.execute_input":"2023-12-12T19:14:35.062376Z","iopub.status.idle":"2023-12-12T19:14:35.080575Z","shell.execute_reply.started":"2023-12-12T19:14:35.062349Z","shell.execute_reply":"2023-12-12T19:14:35.079603Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(np.count_nonzero(lengths<200)) #some statistics","metadata":{"papermill":{"duration":0.020767,"end_time":"2023-12-11T19:07:22.399876","exception":false,"start_time":"2023-12-11T19:07:22.379109","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-12-12T19:14:36.424987Z","iopub.execute_input":"2023-12-12T19:14:36.425353Z","iopub.status.idle":"2023-12-12T19:14:36.431003Z","shell.execute_reply.started":"2023-12-12T19:14:36.425327Z","shell.execute_reply":"2023-12-12T19:14:36.430029Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"autoregressive_telescope=6","metadata":{"execution":{"iopub.status.busy":"2023-12-12T19:14:39.137962Z","iopub.execute_input":"2023-12-12T19:14:39.138644Z","iopub.status.idle":"2023-12-12T19:14:39.142786Z","shell.execute_reply.started":"2023-12-12T19:14:39.138611Z","shell.execute_reply":"2023-12-12T19:14:39.141787Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Build the training sequences\nX_train = []\ny_train = []\nfor i, time_series in enumerate(X_train_raw):\n    dataset_tmp, labels_tmp = build_sequences(time_series[valid_indices_train[i, 0]:], window = 24, stride = 3, telescope = autoregressive_telescope)\n    X_train.extend(dataset_tmp)\n    y_train.extend(labels_tmp)\nX_train = np.array(X_train)\ny_train = np.array(y_train)","metadata":{"papermill":{"duration":1.366515,"end_time":"2023-12-11T19:07:23.814976","exception":false,"start_time":"2023-12-11T19:07:22.448461","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-12-12T19:14:40.465578Z","iopub.execute_input":"2023-12-12T19:14:40.466441Z","iopub.status.idle":"2023-12-12T19:14:53.132400Z","shell.execute_reply.started":"2023-12-12T19:14:40.466407Z","shell.execute_reply":"2023-12-12T19:14:53.131348Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Build the validation sequences\nX_val = []\ny_val = []\nfor i, time_series in enumerate(X_validation_raw):\n    dataset_tmp, labels_tmp = build_sequences(time_series[valid_indices_validation[i, 0]:], window = 24, stride = 3, telescope = autoregressive_telescope)\n    X_val.extend(dataset_tmp)\n    y_val.extend(labels_tmp)\nX_val = np.array(X_val)\ny_val = np.array(y_val)","metadata":{"papermill":{"duration":0.378951,"end_time":"2023-12-11T19:07:24.208447","exception":false,"start_time":"2023-12-11T19:07:23.829496","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-12-12T19:14:56.921457Z","iopub.execute_input":"2023-12-12T19:14:56.922400Z","iopub.status.idle":"2023-12-12T19:14:59.964236Z","shell.execute_reply.started":"2023-12-12T19:14:56.922363Z","shell.execute_reply":"2023-12-12T19:14:59.963219Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(X_train.shape)\nprint(y_train.shape)","metadata":{"papermill":{"duration":0.021231,"end_time":"2023-12-11T19:07:24.243004","exception":false,"start_time":"2023-12-11T19:07:24.221773","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-12-12T19:15:01.794641Z","iopub.execute_input":"2023-12-12T19:15:01.795551Z","iopub.status.idle":"2023-12-12T19:15:01.801789Z","shell.execute_reply.started":"2023-12-12T19:15:01.795504Z","shell.execute_reply":"2023-12-12T19:15:01.800707Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#A simple function to print the sequences\ndef inspect_multivariate(X, y, telescope, idx=None):\n    random_indices = np.random.choice(X.shape[0], 10, replace=False)\n\n    # Plot each selected time series in a separate subplot\n    num_plots = len(random_indices)\n    fig, axs = plt.subplots(num_plots, 1, figsize=(10, 2 * num_plots))\n\n    for i, index in enumerate(random_indices):\n        axs[i].plot(np.arange(len(X[0,:])), X[index,:])\n        axs[i].scatter(np.arange(len(X[0,:]), len(X[0,:])+telescope), y[index,:], color='orange')\n        axs[i].set_title(f'Time Series {index}')\n        axs[i].set_xlabel('Time')\n        axs[i].set_ylabel('Value')\n\n    plt.tight_layout()\n    plt.show()","metadata":{"papermill":{"duration":0.02453,"end_time":"2023-12-11T19:07:24.280569","exception":false,"start_time":"2023-12-11T19:07:24.256039","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-12-12T15:59:52.989470Z","iopub.execute_input":"2023-12-12T15:59:52.989862Z","iopub.status.idle":"2023-12-12T15:59:52.998472Z","shell.execute_reply.started":"2023-12-12T15:59:52.989822Z","shell.execute_reply":"2023-12-12T15:59:52.997559Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"inspect_multivariate(X_train, y_train, autoregressive_telescope)","metadata":{"papermill":{"duration":1.921614,"end_time":"2023-12-11T19:07:26.215430","exception":false,"start_time":"2023-12-11T19:07:24.293816","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-12-12T15:59:55.322743Z","iopub.execute_input":"2023-12-12T15:59:55.323520Z","iopub.status.idle":"2023-12-12T15:59:57.297564Z","shell.execute_reply.started":"2023-12-12T15:59:55.323485Z","shell.execute_reply":"2023-12-12T15:59:57.296613Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"input_shape = X_train.shape[1:]\noutput_shape = y_train.shape[1:]\nbatch_size = 1024\nepochs = 600","metadata":{"papermill":{"duration":0.023703,"end_time":"2023-12-11T19:07:26.255353","exception":false,"start_time":"2023-12-11T19:07:26.231650","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-12-12T16:01:49.444604Z","iopub.execute_input":"2023-12-12T16:01:49.445215Z","iopub.status.idle":"2023-12-12T16:01:49.449780Z","shell.execute_reply.started":"2023-12-12T16:01:49.445183Z","shell.execute_reply":"2023-12-12T16:01:49.448791Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(output_shape)","metadata":{"execution":{"iopub.status.busy":"2023-12-12T17:53:25.188580Z","iopub.execute_input":"2023-12-12T17:53:25.189009Z","iopub.status.idle":"2023-12-12T17:53:25.194282Z","shell.execute_reply.started":"2023-12-12T17:53:25.188969Z","shell.execute_reply":"2023-12-12T17:53:25.193172Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def build_CONV_LSTM_model(input_shape, output_shape):#merge convolution and lstm, to extract features and correlate in the time domain\n    # Ensure the input time steps are at least as many as the output time steps\n    assert input_shape[0] >= output_shape[0], \"For this exercise we want input time steps to be >= of output time steps\"\n\n    # Define the input layer with the specified shape\n    input_layer = tfkl.Input(shape=input_shape, name='input_layer')\n\n    # Add a Bidirectional LSTM layer with 64 units\n    x = tfkl.Bidirectional(tfkl.LSTM(64, return_sequences=True, name='lstm'), name='bidirectional_lstm')(input_layer)\n\n    # Add a 1D Convolution layer with 128 filters and a kernel size of 3\n    x = tfkl.Conv1D(128, 3, padding='same', activation='relu', name='conv')(x)\n\n    # Add a final Convolution layer to match the desired output shape\n    output_layer = tfkl.Conv1D(output_shape[1], 3, padding='same', name='output_layer')(x)\n\n    # Calculate the size to crop from the output to match the output shape\n    crop_size = output_layer.shape[1] - output_shape[0]\n\n    # Crop the output to the desired length\n    output_layer = tfkl.Cropping1D((0, crop_size), name='cropping')(output_layer)\n    \n    # Construct the model by connecting input and output layers\n    model = tf.keras.Model(inputs=input_layer, outputs=output_layer, name='CONV_LSTM_model')\n\n    # Compile the model with Mean Squared Error loss and Adam optimizer\n    model.compile(loss=tf.keras.losses.MeanSquaredError(), optimizer=tf.keras.optimizers.Adam())\n\n    return model","metadata":{"papermill":{"duration":0.028662,"end_time":"2023-12-11T19:07:26.299995","exception":false,"start_time":"2023-12-11T19:07:26.271333","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-12-12T16:01:50.278608Z","iopub.execute_input":"2023-12-12T16:01:50.278966Z","iopub.status.idle":"2023-12-12T16:01:50.288217Z","shell.execute_reply.started":"2023-12-12T16:01:50.278938Z","shell.execute_reply":"2023-12-12T16:01:50.287054Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = build_CONV_LSTM_model(input_shape, output_shape)\nmodel.summary()\ntfk.utils.plot_model(model, expand_nested=True, show_shapes=True)","metadata":{"papermill":{"duration":3.878741,"end_time":"2023-12-11T19:07:30.194695","exception":false,"start_time":"2023-12-11T19:07:26.315954","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-12-12T16:01:51.785115Z","iopub.execute_input":"2023-12-12T16:01:51.785802Z","iopub.status.idle":"2023-12-12T16:01:52.409899Z","shell.execute_reply.started":"2023-12-12T16:01:51.785771Z","shell.execute_reply":"2023-12-12T16:01:52.408890Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Train the model\nhistory = model.fit(\n    x = X_train,\n    y = y_train,\n    batch_size = batch_size,\n    epochs = epochs,\n    validation_data=(X_val, y_val),\n    callbacks = [\n        tfk.callbacks.EarlyStopping(monitor='val_loss', mode='min', patience=12, restore_best_weights=True),\n        tfk.callbacks.ReduceLROnPlateau(monitor='val_loss', mode='min', patience=10, factor=0.1, min_lr=1e-5)\n    ]\n).history","metadata":{"papermill":{"duration":1493.907495,"end_time":"2023-12-11T19:32:24.121193","exception":false,"start_time":"2023-12-11T19:07:30.213698","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-12-12T16:01:54.039669Z","iopub.execute_input":"2023-12-12T16:01:54.040360Z","iopub.status.idle":"2023-12-12T17:33:37.726117Z","shell.execute_reply.started":"2023-12-12T16:01:54.040328Z","shell.execute_reply":"2023-12-12T17:33:37.725044Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.save('forecasting_all.h5')","metadata":{"execution":{"iopub.status.busy":"2023-12-12T17:33:58.051735Z","iopub.execute_input":"2023-12-12T17:33:58.052654Z","iopub.status.idle":"2023-12-12T17:33:58.091893Z","shell.execute_reply.started":"2023-12-12T17:33:58.052620Z","shell.execute_reply":"2023-12-12T17:33:58.091050Z"},"trusted":true},"execution_count":null,"outputs":[]}]}